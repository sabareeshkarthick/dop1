{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd61cec8",
   "metadata": {},
   "source": [
    "# Design Optimization\n",
    "## homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca4ec98",
   "metadata": {},
   "source": [
    "### question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c6c093",
   "metadata": {},
   "source": [
    "$f=f(x_{1},x_{2}) = 2x_{1}^2-4x_{1}x_{2}+1.5x_{2}^2+x_{2}$<br/>\n",
    "$g(f) = \\begin{bmatrix}\\frac{\\partial f}{\\partial x_{1}} \\\\ \\frac{\\partial f}{\\partial x_{2}} \\end{bmatrix} = \\begin{bmatrix} 4x_{1}-4x_{2} \\\\ -4x_{1}+3x_{2}+1 \\end{bmatrix}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7f14c9",
   "metadata": {},
   "source": [
    "For stationary point $ g(f) = 0 $<br/>\n",
    "Therefore,$\\begin{bmatrix}4x_{1}-4x_{2}\\\\-4x_{1}+3x_{2}+1 \\end{bmatrix}=\\begin{bmatrix} 0\\\\0 \\end{bmatrix} $ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2896a03f",
   "metadata": {},
   "source": [
    "$4x_{1}-4x_{2}= 0$ <br/>\n",
    "$-4x_{1}+3x_{2}=-1$<br/>\n",
    "Using elimination method we get $x_{1}=1$ , $x_{2}=1$ <br/>\n",
    "Therefore the stationary point $(x_{1},x_{2})=(1,1)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081c5b9d",
   "metadata": {},
   "source": [
    "$ H(f) = \\begin{bmatrix}\\frac{\\partial ^2 f}{\\partial x_{1}^2} & \\frac{\\partial ^2 f}{\\partial x_{1}\\partial x_{2}} \\\\ \\frac{\\partial ^2 f}{\\partial x_{2}\\partial x_{1}} & \\frac{\\partial ^2 f}{\\partial x_{2}^2}\\end{bmatrix} = \\begin{bmatrix} 4 & -4 \\\\ -4 & 3\\end{bmatrix}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03934127",
   "metadata": {},
   "source": [
    "Eigen value :<br/> $AX=\\lambda X$<br/>\n",
    "$(A-\\lambda I)X=0$<br/>\n",
    "$|A-\\lambda I|=0$<br/><br/>\n",
    "$\\begin{vmatrix} 4-\\lambda & -4 \\\\ -4 & 3-\\lambda\\end{vmatrix}=0$<br/><br/>\n",
    "$(4-\\lambda)(3-\\lambda)-16=0$<br/>\n",
    "$12-4\\lambda-3\\lambda+\\lambda ^2-16=0$<br/>\n",
    "$\\lambda^2-7\\lambda-4=0$<br/>\n",
    "$\\lambda = \\frac{-b\\pm \\sqrt{b^2-4ac}}{2a}$<br/>\n",
    "$\\lambda = \\frac{7\\pm \\sqrt{49-4(1)(-4)}}{2(1)}$<br/>\n",
    "$\\lambda = \\frac{7\\pm \\sqrt{65}}{2}$<br/>\n",
    "$\\lambda_{1} = \\frac{7+\\sqrt{65}}{2}  ,\\lambda_{2} = \\frac{7-\\sqrt{65}}{2} $<br/>\n",
    "$\\lambda_{1}=7.5311288 , \\lambda_{2}=-0.5311288$<br/><br/>\n",
    "Since the eigen values of hessian has both positive and negative values, the function is indefinite.<br/>\n",
    "Therefore,the stationary point $(1,1)$ is a saddle point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783c1d73",
   "metadata": {},
   "source": [
    "Taylors expansion,<br/>\n",
    "$f(x_{1},x_{2})=f(x_{1},x_{2})+[g(f)]^T (x-x_{0})+\\frac{1}{2} (x-x_{0})^T H(f)(x-x_{0})$<br/>\n",
    "for $(x_{1},x_{2})=(1,1)$<br/>\n",
    "$f(x_{1},x_{2})=f(1,1)+\\begin{bmatrix} 4(1)-4(1) & -4(1)+3(1)+1 \\end{bmatrix} \\begin{bmatrix}x_{1}-1 \\\\ x_{2}-1\\end{bmatrix}+\\frac{1}{2}\\begin{bmatrix}x_{1}-1 & x_{2}-1\\end{bmatrix}\\begin{bmatrix}4 & -4 \\\\ -4 & 3\\end{bmatrix}\\begin{bmatrix}x_{1}-1 \\\\ x_{2}-1\\end{bmatrix}$<br/>\n",
    "let $x_{1}-1=\\partial x_{1} , x_{2}-1=\\partial x_{2}$<br/>\n",
    "$f(x_{1},x_{2})=f(1,1)+0+\\frac{1}{2}\\begin{bmatrix}\\partial x_{1} & \\partial x_{2}\\end{bmatrix}\\begin{bmatrix}4 & -4 \\\\ -4 & 3\\end{bmatrix}\\begin{bmatrix}\\partial x_{1} \\\\ \\partial x_{2}\\end{bmatrix}$<br/>\n",
    "$=f(1,1)+\\frac{1}{2}\\begin{bmatrix}4\\partial x_{1}-4\\partial x_{2} & -4\\partial x_{1}+3\\partial x_{2}\\end{bmatrix}\\begin{bmatrix}\\partial x_{1} \\\\ \\partial x_{2}\\end{bmatrix}$<br/>\n",
    "$=f(1,1)+\\frac{1}{2} [(4 \\partial x_{1}^2 - 4 \\partial x_{1} \\partial x_{2} - 4 \\partial x_{1} \\partial x_{2} + 3 \\partial x_{2}^2)]$<br/>\n",
    "$=f(1,1)+\\frac{1}{2} [(4 \\partial x_{1}^2 - 2 \\partial x_{1} \\partial x_{2} - 6 \\partial x_{1} \\partial x_{2} + 3 \\partial x_{2}^2)]$<br/>\n",
    "$=f(1,1)+\\frac{1}{2} [(2\\partial x_{1}(2\\partial x_{1}-\\partial x_{2})-3\\partial x_{2}(2\\partial x_{1}-\\partial x_{2})]$<br/>\n",
    "$=f(1,1)+\\frac{1}{2} [(2\\partial x_{1}-\\partial x_{2})(2\\partial x_{1} -3\\partial x_{2})]$<br/>\n",
    "$=f(1,1)+ (1\\partial x_{1}-\\frac{1}{2} \\partial x_{2})(1\\partial x_{1} -\\frac{3}{2} \\partial x_{2})$<br/>\n",
    "let $a=1,b=\\frac{1}{2},c=1,d=\\frac{3}{2}$<br/>\n",
    "$\\implies f(x_{1},x_{2})=f(1,1)+(a\\partial x_{1}-b \\partial x_{2})(c\\partial x_{1} -d \\partial x_{2})$<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f94aed",
   "metadata": {},
   "source": [
    "Direction of downslopes,<br/>\n",
    "$f(x_{1},x_{2})-f(1,1)=(a\\partial x_{1}-b \\partial x_{2})(c\\partial x_{1} -d \\partial x_{2})<0$<br/>\n",
    "$\\implies (a\\partial x_{1}-b \\partial x_{2})(c\\partial x_{1} -d \\partial x_{2})<0$<br/>\n",
    "So either $(a\\partial x_{1}-b \\partial x_{2})$ or $(c\\partial x_{1} -d \\partial x_{2})$ should be negative,not both and $a\\partial x_{1}\\neq b \\partial x_{2},c\\partial x_{1} \\neq d \\partial x_{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2816ba55",
   "metadata": {},
   "source": [
    "### question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d1c3ca",
   "metadata": {},
   "source": [
    "#### 2(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea895ab3",
   "metadata": {},
   "source": [
    "Plane $=x_{1}+2x_{2}+3x_{3}=1$<br/>\n",
    "Nearest to point $(-1,0,1)^T$<br/>\n",
    "To find the nearest point we should minimize the difference between the point we need to find$(x_{1},x_{2},x_{3})$ and point$(-1,0,1)$<br/>\n",
    "$\\implies f=f(x_{1},x_{2},x_{3})=min((x_{1}-(-1))^2+(x_{2}-0)^2+(x_{3}-1)^2)$<br/>\n",
    "$\\implies$Objective function,$$f(x_{1},x_{2},x_{3})=min((x_{1}+1)^2+x_{2}^2+(x_{3}-1)^2)$$<br/>\n",
    "Constrain:<br/>\n",
    "Since the point should be in the plane $x_{1}+2x_{2}+3x_{3}=1$,it must satisfy the equation of this plane.<br/>\n",
    "Therefore constrain is,$$x_{1}+2x_{2}+3x_{3}=1$$<br/>\n",
    "To make the function unconstrained n,substitue $x_{1}=1-2x_{2}-3x_{3}$ in the objective function$f$<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27683f1c",
   "metadata": {},
   "source": [
    "$f(x_{1},x_{2},x_{3})=(1-2x_{2}-3x_{3}+1)^2+x_{2}^2+(x_{3}-1)^2$<br/>\n",
    "$=(2-2x_{2}-3x_{3})(2-2x_{2}-3x_{3})+x_{2}^2+x_{3}^2+1-2x_{3}$<br/>\n",
    "$=4-4x_{2}-6x_{3}-4x_{2}+4x_{2}^2+6x_{2}x_{3}-6x_{3}+6x_{2}x_{3}+9x_{3}^2+x_{2}^2+x_{3}^2+1-2x_{3}$<br/>\n",
    "$=5x_{2}^2-8x_{2}+12x_{2}x_{3}+10x_{3}^2-14x_{3}+5$<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b90b66e",
   "metadata": {},
   "source": [
    "$g(x)=\\begin{bmatrix} \\frac{\\partial f}{\\partial x_{2}}\\\\ \\frac{\\partial f}{\\partial x_{3}}\\end{bmatrix}=\\begin{bmatrix} 10x_{2}-8+12x_{3} \\\\ 12x_{2}+20x_{3}-14 \\end{bmatrix} $<br/>\n",
    "To find minimum,$g(X)=0$<br/>\n",
    "$\\implies g(x)=\\begin{bmatrix} 10x_{2}-8+12x_{3} \\\\ 12x_{2}+20x_{3}-14 \\end{bmatrix} =\\begin{bmatrix}  0 \\\\ 0 \\end{bmatrix}$<br/>\n",
    "$10x_{2}-8+12x_{3}=0 \\tag 1$<br/>\n",
    "$12x_{2}+20x_{3}-14=0 \\tag 2$<br/>\n",
    "divide $eq(1)$ by 2$ 5x_{2}+6x_{3}-4=0 \\tag 3$<br/>\n",
    "divide $eq(2)$ by 2$ 6x_{2}+10x_{3}-7=0 \\tag 4$<br/>\n",
    "$eq(3)$* -6 $  -30x_{2}-36x_{3}+24=0 \\tag 5$<br/>\n",
    "$eq(4)$*  5 $  30x_{2}+50x_{3}-35=0 \\tag 6$<br/>\n",
    "$eq(5)+eq(6)$ $\\implies 14 x_{3}-11=0$<br/><br/>\n",
    "$\\implies x_{3}=\\frac{11}{14}$<br/><br/>\n",
    "substitute $x_{3}$ in $-eq(3)$ we get,<br/>\n",
    "$6x_{2}+10(\\frac{11}{14})-7=0$<br/>\n",
    "$6x_{2}+\\frac{110-98}{14}=0$<br/>\n",
    "$6x_{2}+\\frac{12}{14}=0$<br/>\n",
    "$6x_{2}=-\\frac{12}{14}$<br/><br/>\n",
    "$\\implies x_{2}=-\\frac{1}{7}$<br/><br/>\n",
    "substitute $x_{2}$ and $x_{3}$ values in constrain equation, $x_{1}=1-2x_{2}-3x_{3}$ ,we get<br/>\n",
    "$x_{1}=1-2(\\frac {-1}{7})-3(\\frac {11}{14})$<br/>\n",
    "$=1+\\frac{2}{7}-\\frac{33}{14}$<br/>\n",
    "$=1-\\frac{29}{14}$<br/><br/>\n",
    "$\\implies x_{1}=-\\frac{15}{14}$<br/><br/>\n",
    "$\\implies$ the nearest point $(x_{1},x_{2},x_{3})=(-\\frac{15}{14},-\\frac{1}{7},\\frac{11}{14})$<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f3caf0",
   "metadata": {},
   "source": [
    "$ H(f) = \\begin{bmatrix}\n",
    " \\frac{\\partial ^2 f}{\\partial x_{2}^2} & \\frac{\\partial ^2 f}{\\partial x_{2}\\partial x_{3}} \\\\   \\frac{\\partial ^2 f}{\\partial x_{3}\\partial x_{2}} & \\frac{\\partial ^2 f}{\\partial x_{3}^2}\n",
    "\\end{bmatrix} $<br/><br/>\n",
    "$ H(f)= \\begin{bmatrix} 10&12\\\\12&20 \\end{bmatrix}$<br/><br/>\n",
    "Eigen values:<br/>\n",
    "$(A-\\lambda I)X=0$<br/>\n",
    "$|A-\\lambda I|=0$<br/><br/>\n",
    "$\\begin{vmatrix}10-\\lambda &12\\\\12&20-\\lambda \\end{vmatrix}=0$<br/><br/>\n",
    "$\\implies[(10-\\lambda)(20-\\lambda)-(12)(12)]=0$<br/>\n",
    "$[200-10\\lambda-20\\lambda+\\lambda^2-144]=0$<br/>\n",
    "$[\\lambda^2-30\\lambda+56]=0$<br/>\n",
    "$[(\\lambda -28)(\\lambda -2)]=0$<br/>\n",
    "$\\lambda_{1}=28,\\lambda_{2}=2$<br/><br/>\n",
    "Since all the eigen values are $> 0$ ,the Hessian is positive definite.<br/>\n",
    "since the Hessian is P.D everywhere this function is a convex function.<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703b1e02",
   "metadata": {},
   "source": [
    "#### 2(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472881ac",
   "metadata": {},
   "source": [
    "##### gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "07accca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration0=(x2,x3)=[ 1.36591479 -0.19498747]\n",
      "iteration1=(x2,x3)=[0.1233057  0.36983484]\n",
      "iteration2=(x2,x3)=[0.20852451 0.55731621]\n",
      "iteration3=(x2,x3)=[-0.08086982  0.68885909]\n",
      "iteration4=(x2,x3)=[-0.061023    0.73252209]\n",
      "iteration5=(x2,x3)=[-0.12842076  0.76315744]\n",
      "iteration6=(x2,x3)=[-0.12379858  0.77332622]\n",
      "iteration7=(x2,x3)=[-0.13949502  0.78046097]\n",
      "iteration8=(x2,x3)=[-0.13841855  0.7828292 ]\n",
      "iteration9=(x2,x3)=[-0.14207413  0.78449083]\n",
      "iteration10=(x2,x3)=[-0.14182343  0.78504237]\n",
      "iteration11=(x2,x3)=[-0.14267478  0.78542935]\n",
      "iteration12=(x2,x3)=[-0.1426164  0.7855578]\n",
      "iteration13=(x2,x3)=[-0.14281467  0.78564793]\n",
      "iteration14=(x2,x3)=[-0.14280108  0.78567784]\n",
      "iteration15=(x2,x3)=[-0.14284725  0.78569883]\n",
      "iteration16=(x2,x3)=[-0.14284409  0.7857058 ]\n",
      "iteration17=(x2,x3)=[-0.14285484  0.78571069]\n",
      "iteration18=(x2,x3)=[-0.1428541   0.78571231]\n",
      "iteration19=(x2,x3)=[-0.14285661  0.78571345]\n",
      "iteration20=(x2,x3)=[-0.14285643  0.78571383]\n",
      "iteration21=(x2,x3)=[-0.14285702  0.78571409]\n",
      "iteration22=(x2,x3)=[-0.14285698  0.78571418]\n",
      "iteration23=(x2,x3)=[-0.14285711  0.78571424]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "def func(x):\n",
    "    f=5*x[0]**2-8*x[0]+12*x[0]*x[1]+10*x[1]**2-14*x[1]+5\n",
    "    return f\n",
    "def grad(x):\n",
    "    g=np.array([10*x[0]-8+12*x[1],12*x[0]+20*x[1]-14])\n",
    "    return g\n",
    "def hess(x):\n",
    "    h=np.array([[10,12],[12,20]])\n",
    "    return h\n",
    "def gradmet(x0):\n",
    "        i=0\n",
    "        c=0\n",
    "        f=func(x0)\n",
    "        g=grad(x0)\n",
    "        h=hess(x0)\n",
    "        gt=np.transpose(g)\n",
    "        ng=LA.norm(g)\n",
    "        while (ng>0.000001):\n",
    "            f=func(x0)\n",
    "            g=grad(x0)\n",
    "            h=hess(x0)\n",
    "            gt=np.transpose(g)\n",
    "            ng=LA.norm(g)\n",
    "            a=(np.dot(gt,g))/(np.dot((np.dot(gt,h)),g))\n",
    "            x0=x0-a*g\n",
    "            print(\"iteration{}=(x2,x3)={}\".format(i,x0))\n",
    "            if i==100:\n",
    "                 break\n",
    "            i=i+1\n",
    "\n",
    "gradmet([1,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb15afa",
   "metadata": {},
   "source": [
    "###### result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be89e828",
   "metadata": {},
   "source": [
    "For initial point $(1,1)$<br/>\n",
    "$iteration0,(x2,x3)=[0.49751518,0.35394809]$<br/>\n",
    "$iteration1,(x2,x3)=[-0.07417103,0.79859293]$<br/>\n",
    "$iteration2,(x2,x3)=[-0.10437054,0.75976499]$<br/>\n",
    "$iteration3,(x2,x3)=[-0.13872908,0.7864883 ]$<br/>\n",
    "$iteration4,(x2,x3)=[-0.14054408,0.78415472]$<br/>\n",
    "$iteration5,(x2,x3)=[-0.14260905,0.7857608 ]$<br/>\n",
    "$iteration6,(x2,x3)=[-0.14271813,0.78562056]$<br/>\n",
    "$iteration7,(x2,x3)=[-0.14284223,0.78571708]$<br/>\n",
    "$iteration8,(x2,x3)=[-0.14284879,0.78570865]$<br/>\n",
    "$iteration9,(x2,x3)=[-0.14285625,0.78571445]$<br/>\n",
    "$iteration10,(x2,x3)=[-0.14285664,0.78571395]$<br/>\n",
    "$iteration11,(x2,x3)=[-0.14285709,0.7857143 ]$<br/>\n",
    "$iteration12,(x2,x3)=[-0.14285711,0.78571427]$<br/>\n",
    "$iteration13,(x2,x3)=[-0.14285714,0.78571429]$<br/><br/><br/>\n",
    "For initial point $(100,200)$<br/>\n",
    "$iteration0,(x2,x3)=[-21.15151437,14.77247833]$<br/>\n",
    "$iteration1,(x2,x3)=[-0.04992271,0.97058884]$<br/>\n",
    "$iteration2,(x2,x3)=[-0.16235357,0.79869426]$<br/>\n",
    "$iteration3,(x2,x3)=[-0.1427709 ,0.78588585]$<br/>\n",
    "$iteration4,(x2,x3)=[-0.14287524,0.78572633]$<br/>\n",
    "$iteration5,(x2,x3)=[-0.14285706,0.78571444]$<br/>\n",
    "$iteration6,(x2,x3)=[-0.14285716,0.7857143 ]$<br/>\n",
    "$iteration7,(x2,x3)=[-0.14285714,0.78571429]$<br/><br/><br/>\n",
    "For initial point $(3000,2700)$<br/>\n",
    "$iteration0,(x2,x3)=[ 93685.80183447,133493.25176107]$<br/>\n",
    "$iteration1,(x2,x3)=[ 3015.23281209,-2009.99676567]$<br/>\n",
    "$iteration2,(x2,x3)=[3.16384063,5.49740547]$<br/>\n",
    "$iteration3,(x2,x3)=[-0.03642777,0.71474259]$<br/>\n",
    "$iteration4,(x2,x3)=[-0.14274043,0.78588059]$<br/>\n",
    "$iteration5,(x2,x3)=[-0.14285339,0.78571178]$<br/>\n",
    "$iteration6,(x2,x3)=[-0.14285714,0.78571429]$<br/>\n",
    "$iteration7,(x2,x3)=[-0.14285714,0.78571429]$<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90273a0b",
   "metadata": {},
   "source": [
    "##### Newton's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d1f0e44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration0=(x2,x3)=[-0.14285714  0.78571429]\n",
      "iteration1=(x2,x3)=[-0.14285714  0.78571429]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "def func(x):\n",
    "    f=5*x[0]**2-8*x[0]+12*x[0]*x[1]+10*x[1]**2-14*x[1]+5\n",
    "    return f\n",
    "def grad(x):\n",
    "    g=np.array([10*x[0]-8+12*x[1],12*x[0]+20*x[1]-14])\n",
    "    return g\n",
    "def hess(x):\n",
    "    h=np.array([[10,12],[12,20]])\n",
    "    return h\n",
    "def newmet(x0):\n",
    "        i=0\n",
    "        c=0\n",
    "        f=func(x0)\n",
    "        g=grad(x0)\n",
    "        h=hess(x0)\n",
    "        gt=np.transpose(g)\n",
    "        ng=LA.norm(g)\n",
    "        while (ng>0.000001):\n",
    "            f=func(x0)\n",
    "            g=grad(x0)\n",
    "            h=hess(x0)\n",
    "            hi=np.linalg.inv(h)\n",
    "            gt=np.transpose(g)\n",
    "            ng=LA.norm(g)\n",
    "            a=1\n",
    "            \n",
    "            x0=x0-a*(np.dot(hi,g))\n",
    "            print(\"iteration{}=(x2,x3)={}\".format(i,x0))\n",
    "            a=(np.dot(gt,g))/(np.dot((np.dot(gt,h)),g))\n",
    "            if i==100:\n",
    "                 break\n",
    "            i=i+1\n",
    "\n",
    "newmet([1,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668cce50",
   "metadata": {},
   "source": [
    "###### result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c1f796",
   "metadata": {},
   "source": [
    "For initial point $(1,1)$<br/>\n",
    "$iteration0,(x2,x3)=[-0.14285714,0.78571429]$<br/>\n",
    "$iteration1,(x2,x3)=[-0.14285714,0.78571429]$<br/><br/><br/>\n",
    "For initial point $(100,200)$<br/>\n",
    "$iteration0,(x2,x3)=[-0.14285714,0.78571429]$<br/>\n",
    "$iteration1,(x2,x3)=[-0.14285714,0.78571429]$<br/><br/><br/>\n",
    "For initial point $(3000,2700)$<br/>\n",
    "$iteration0,(x2,x3)=[-0.14285714,0.78571429]$<br/>\n",
    "$iteration1,(x2,x3)=[-0.14285714,0.78571429]$<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9228199f",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed355d0b",
   "metadata": {},
   "source": [
    "We can see that the gradient method takes multiple steps depending on step size to achieve the optimal solution ,but the Newton's method directly gives the solution in a single step. This is because the function is quadratic so the second order taylor approximation will provide the optimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581d4bed",
   "metadata": {},
   "source": [
    "### question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf6a98d",
   "metadata": {},
   "source": [
    "To prove: Hyperplane is a convex set<br/>\n",
    "Hyperplane in $\\mathbb{R} ^n$ , $a^Tx=c$ for $x\\in \\mathbb{R} ^n$<br/>\n",
    "consider hyperplane, $$ f=\\{x    \\mid  where,x\\in\\mathbb{R} ^n,a^Tx=c\\}$$<br/>\n",
    "Let $x_{1}$ and $x_{2}$ be any two points in hyperplane f,<br/>\n",
    "$\\implies x_{1}\\in\\mathbb{R} , x_{2}\\in\\mathbb{R}$<br/>\n",
    "$a^Tx_{1}=c , a^Tx_{2}=c$<br/>\n",
    "$\\forall \\lambda\\in [0,1]$ , $\\forall (x_{1},x_{2})\\in x $<br/>\n",
    "$z=\\lambda x_{1}+(1-\\lambda)x_{2}$<br/>\n",
    "To check,$a^Tx=c$<br/>\n",
    "$a^Tz=a^T(\\lambda x_{1}+(1-\\lambda)x_{2})=\\lambda a^Tx_{1}+(1-\\lambda)a^Tx_{2}=c$<br/>\n",
    "Therefore $z=\\lambda x_{1}+(1-\\lambda x_{2})\\in$ hyperplane $f$<br/>\n",
    "$\\implies$ hyperplane is a convex set<br/>\n",
    "hence proved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f430ac4f",
   "metadata": {},
   "source": [
    "### question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9084784",
   "metadata": {},
   "source": [
    "#### 4(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41ed98d",
   "metadata": {},
   "source": [
    "$ H(I,I_{t})=\\{\\frac{I_{t}}{I}$  $| if I\\le I_{t}$  ,  $\\frac{I}{I_{t}}$   $| if I_{t}\\le I \\} $<br/>\n",
    "let $ H_{1}=\\frac{I_{t}}{I}$  $| if I\\le I_{t}$<br/>\n",
    "let $ H_{2}=\\frac{I}{I_{t}}$   $| if I_{t}\\le I$<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6998c133",
   "metadata": {},
   "source": [
    "![4a.png](4a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3f8c2a",
   "metadata": {},
   "source": [
    "You can see that the function $H_{1}$ is monotonically decreasing while the function $H_{2}$ is linear. Therefore the solution should be the intersection of the two functions $H_{1}$ and $H_{2}$. The solution cannot be elsewhere because it will to slip down to the lowest value.<br/>\n",
    "At the intersection point, all the functions of $H_{1}$ will be equal and similarly all the functions of $H_{2}$ will be equal<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8427c57f",
   "metadata": {},
   "source": [
    "$\\implies$<br/>\n",
    "$\\frac{a_{1}^T p}{I_{t}} = \\frac{a_{2}^T p}{I_{t}}= .......=\\frac{a_{n}^T p}{I_{t}} $<br/>\n",
    "$\\frac{I_{t}}{(a_{1}^*)^T p} = \\frac{I_{t}}{(a_{2}^*)^T p}= .......=\\frac{I_{t}}{(a_{n}^*)^T p} $<br/>\n",
    "$\\implies \\frac{a_{1}^T p}{I_{t}}-\\frac{a_{2}^T p}{I_{t}}=0$ <br/>\n",
    "$\\frac{a_{1}^T p - a_{2}^T p}{I_{t}}=0$<br/>\n",
    "$(a_{1} - a_{2})^T p=0$<br/>\n",
    "similarly, $(a_{2} - a_{3})^T p=0, (a_{3} - a_{4})^T p=0, (a_{4} - a_{5})^T p=0 ,.............. $ <br/>\n",
    "These constrains are in form $A^T p=0$<br/>\n",
    "$\\implies$ these constrains are linear and our optimization function is,<br/>\n",
    "$$ f=\\underset{p}{min} =\\frac{I_{t}}{a^T p} $$<br/>\n",
    "$$ st:A^T p=0$$<br/>\n",
    "$\\frac{\\partial f}{\\partial p}=-\\frac{I_{t}}{a^T p^2}$<br/>\n",
    "$\\frac{\\partial^2 f}{\\partial p^2}=2\\frac{I_{t}}{a^T p^3}$<br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e8e621",
   "metadata": {},
   "source": [
    "Since $p$ is the power output of $n$ lamps which is positive, the hessian is positive.<br/>\n",
    "Since the hessian is positive this function is strictly convex with respect to $p$.<br/>\n",
    "Since we are taking the max of all convex function,This problem will also be convex.<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f2a02c",
   "metadata": {},
   "source": [
    "#### 4(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d21455",
   "metadata": {},
   "source": [
    "Take any ten lamps from n lamps<br/>\n",
    "$$ C_{n}^{10}  =\\begin{Bmatrix} p_{1}+p_{2}+...+p_{10} \\le p^* \\\\ p_{2}+p_{3}+...+p_{11} \\le p^* \\\\ .\\\\.\\\\.\\\\p_{n-9}+p_{n-8}+...+p_{n} \\le p^* \\end{Bmatrix} $$<br/>\n",
    "All these constrains are linear with respect to $p$<br/>\n",
    "Since the original function is strictly convex and the feasible set is convex, the problem has a unique solution.<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0d3a69",
   "metadata": {},
   "source": [
    "#### 4(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec313bb7",
   "metadata": {},
   "source": [
    "This problem has $n$ lamps which we assume it is more than 10.<br/>\n",
    "So if no more than 10 lamps are on, that means the $n-10$ lamps are off. If we take two points, one from the function of the lamp that is on and another from the lamp that is off and draw a line between them,we can find that the feasible set is not convex.<br/>\n",
    "Adding this constrain made the problem non-convex, thus we cannot tell how many local solutions we have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e076d74",
   "metadata": {},
   "source": [
    "### question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4d668a",
   "metadata": {},
   "source": [
    "$$Profit,C^*(y)=\\underset{x}{max}(xy-c(x))$$<br/>\n",
    "$C^*(y)=\\underset{x}{max}\\begin{Bmatrix}x_{1}y-c(x_1)\\\\x_2y-c(x_2)\\\\.\\\\.\\\\.\\\\x_ny-c(x_n) \\end{Bmatrix}$<br/>\n",
    "Let $f_1=x_1y-c(x_1)$<br/>\n",
    "$\\frac{\\partial f_1}{\\partial y}=x_1$<br/>\n",
    "$\\frac{\\partial^2 f_1}{\\partial y^2}=0$<br/>\n",
    "The function $f_1$ is a linear function with respect to $y$.<br/>\n",
    "Similarly all the functions $(xy-c(x))$ are linear with respect to y.<br/>\n",
    "$\\implies$ All these functions are convex with respect to y.<br/>\n",
    "Since $C^*(y)$ is the maximum of all the functions which are convex with respect to $y$,$C^*(y)$is also convex with respect to $y$.<br/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
